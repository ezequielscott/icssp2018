{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the dataset\n",
    "\n",
    "First, make sure you have:\n",
    "* A MongoDB server already installed.\n",
    "* A dump of the dataset loaded as a collection\n",
    "* The MongoDB server running.\n",
    "\n",
    "\n",
    "\n",
    "1. Install MongoDB server. Choose the version according to your OS. https://www.mongodb.com/download-center?jmp=nav#community\n",
    "\n",
    "2. Unzip the mongo dump files (.json) into a directory\n",
    "\n",
    "3. Restore/import the dump from the directory by using the command: \n",
    "\n",
    "\t`mongorestore -d <database_name> <directory_backup>`\n",
    "\n",
    "NOTE:\n",
    "The data dump was done using:\n",
    "\t`mongodump -d <database_name> -o <directory_backup>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "\n",
    "from bson import json_util, ObjectId\n",
    "from pandas.io.json import json_normalize\n",
    "import json\n",
    "\n",
    "def _connect_mongo(host, port, username, password, db):\n",
    "    \"\"\" A util for making a connection to mongo \"\"\"\n",
    "\n",
    "    if username and password:\n",
    "        mongo_uri = 'mongodb://%s:%s@%s:%s/%s' % (username, password, host, port, db)\n",
    "        conn = MongoClient(mongo_uri)\n",
    "    else:\n",
    "        conn = MongoClient(host, port)\n",
    "    return conn[db]\n",
    "\n",
    "\n",
    "def read_mongo(db, collection, query={}, host='localhost', port=27017, username=None, password=None, no_id=True):\n",
    "    \"\"\" Read from Mongo and Store into DataFrame \"\"\"\n",
    "\n",
    "    # Connect to MongoDB\n",
    "    db = _connect_mongo(host=host, port=port, username=username, password=password, db=db)\n",
    "\n",
    "    # Make a query to the specific DB and Collection\n",
    "    cursor = db[collection].find(query)\n",
    "    \n",
    "    sanitized = json.loads(json_util.dumps(list(cursor)))\n",
    "    normalized = json_normalize(sanitized)\n",
    "    \n",
    "    # Expand the cursor and construct the DataFrame\n",
    "    df =  pd.DataFrame(normalized)\n",
    "    \n",
    "    # Delete the _id\n",
    "    if no_id:\n",
    "        del df['_id.$oid']\n",
    "\n",
    "    #sf = gl.SFrame(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the data in csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "project_names = ['xd', 'dnn', 'apstud', 'mesos', 'mule', 'nexus', 'timob', 'tistud' ]\n",
    "project_data = {}\n",
    "\n",
    "# reading from the db\n",
    "for p in project_names:\n",
    "    project_data[p] = read_mongo('jira', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing project xd of shape (3691, 154) ...\n",
      "Processing project dnn of shape (1894, 237) ...\n",
      "Processing project apstud of shape (886, 157) ...\n",
      "Processing project mesos of shape (1472, 172) ...\n",
      "Processing project mule of shape (1281, 220) ...\n",
      "Processing project nexus of shape (1071, 158) ...\n",
      "Processing project timob of shape (1990, 180) ...\n",
      "Processing project tistud of shape (2870, 168) ...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "all_projects = pd.DataFrame()\n",
    "for p in project_names:\n",
    "    df = project_data[p]\n",
    "    \n",
    "    print \"Processing project {0} of shape {1} ...\".format(p, df.shape)\n",
    "    \n",
    "    df0 = df[[\n",
    "     'fields.assignee.name',\n",
    "     'fields.components',\n",
    "     'fields.created',\n",
    "     'fields.creator.name',\n",
    "     'fields.description', # User Story description\n",
    "     'fields.fixVersions',\n",
    "     'fields.issuetype.name', \n",
    "     'fields.issuetype.subtask', # true, false\n",
    "     'fields.priority.name', # Minor, Major, Critical, Blocker\n",
    "     'fields.reporter.name',\n",
    "     'fields.resolution.description',\n",
    "     'fields.resolution.name',\n",
    "     'fields.resolutiondate',\n",
    "     'fields.status.id',\n",
    "     'fields.status.name',\n",
    "     'fields.status.statusCategory.name',\n",
    "     'fields.summary',\n",
    "     'fields.updated',\n",
    "     'fields.versions',\n",
    "     'fields.watches.watchCount',\n",
    "     u'key',\n",
    "    ]].copy()\n",
    "    \n",
    "    # List of fields where the story points are stored:\n",
    "    storypoints_fields = {\n",
    "        'apstud':'customfield_10003',\n",
    "        'dnn': 'customfield_10004',\n",
    "        'mesos':'customfield_12310293',\n",
    "        'mule':'customfield_10203',\n",
    "        'timob':'customfield_10003',\n",
    "        'tistud':'customfield_10003',\n",
    "        'xd':'customfield_10142',\n",
    "        'nexus': 'customfield_10132'\n",
    "    }\n",
    "    \n",
    "    df0['storypoints'] = df[ 'fields.' + storypoints_fields[p] ]\n",
    "    \n",
    "    df0['project'] = p\n",
    "    \n",
    "    # transform components from json objet to list of string\n",
    "    df0['fields.components'] = df0['fields.components'].apply(lambda x : [ v['name'] for v in x if v != [] ] )\n",
    "    df0['fields.versions'] = df0['fields.versions'].apply(lambda x : [ v['name'] for v in x if v != [] ] )\n",
    "    df0['fields.fixVersions'] = df0['fields.fixVersions'].apply(lambda x : [ v['name'] for v in x if v != [] ] )\n",
    "  \n",
    "    all_projects = all_projects.append(df0, ignore_index=True)\n",
    "\n",
    "print \"Done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_projects.to_csv(\"jiradataset_issues.csv\", sep=',', encoding='utf-8', doublequote = True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#all_project = pd.read_csv(\"jiradataset_issues.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the changelog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_changelog(data):\n",
    "    changelog = pd.DataFrame()\n",
    "    for i, item in data.iterrows():\n",
    "        \n",
    "        key = item['key']\n",
    "        \n",
    "        histories = pd.DataFrame(item['changelog.histories'])\n",
    "        if not histories.empty:\n",
    "            histories['author'] = histories['author'].apply(lambda x : x['name'] if 'name' in x.keys() else '') \n",
    "        \n",
    "            for j, h in histories.iterrows():\n",
    "                author = h['author']\n",
    "                items = pd.DataFrame(h['items'])\n",
    "\n",
    "                items['key'] = key\n",
    "                items['created'] = h['created']\n",
    "                items['author'] = author\n",
    "\n",
    "                changelog = changelog.append(items, ignore_index=True)\n",
    "            \n",
    "    return changelog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing project xd (3691, 154) ...\n"
     ]
    }
   ],
   "source": [
    "all_changelogs = pd.DataFrame()\n",
    "for p in project_names:\n",
    "    df = project_data[p]\n",
    "    \n",
    "    print \"Processing project {0} {1} ...\".format(p, df.shape)\n",
    "    \n",
    "    changelog = get_changelog(df)\n",
    "    \n",
    "    changelog['project'] = p\n",
    "    \n",
    "    all_changelogs = all_changelogs.append(changelog, ignore_index=True)\n",
    "print \"Done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_changelogs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_changelogs.to_csv(\"jiradataset_changelog.csv\", sep=',', encoding='utf-8', doublequote = True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
